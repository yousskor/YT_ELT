import requests
import json
from datetime import date

import os
from dotenv import load_dotenv 

maxResults = 50
#load_dotenv(dotenv_path="./env")

from airflow.models import    Variable

CHANNEL_HANDLE = Variable.get('CHANNEL_HANDLE')
API_KEY = Variable.get("API_KEY")




def get_paylist_id():
        
        try:
                
            url = f"https://youtube.googleapis.com/youtube/v3/channels?part=contentDetails&forHandle={CHANNEL_HANDLE}&key={API_KEY}"

            response = requests.get(url)

            response.raise_for_status()

            data = response.json()

            #print(json.dumps(data, indent=4))

            channel_items = data["items"][0]

            channel_playlisID = channel_items["contentDetails"]["relatedPlaylists"]['uploads']

            print(channel_playlisID)

            return channel_playlisID
        
        except requests.exceptions.RequestException as e:
              raise e
        
    
def get_video_ids(playlistID):
      
      video_ids = []

      pageToken = None

      base_url = f"https://youtube.googleapis.com/youtube/v3/playlistItems?part=contentDetails&maxResults={maxResults}&playlistId={playlistID}&key={API_KEY}"
      
      try:
           while True:
                 
                 url = base_url

                 if pageToken:
                       
                       url += f"&pageToken={pageToken}"
                       
                 response = requests.get(url)
                
                 response.raise_for_status()
                
                 data = response.json()

                 for item in data.get('items', []):
                 
                    video_id = item['contentDetails']['videoId']

                    video_ids.append(video_id)

                 pageToken = data.get('nextPageToken')

                 if not pageToken:
                       break
                 
           return video_ids

      except requests.exceptions.RequestException as e:
            raise e


def batch_list(video_id_list, batch_size):
      for video_id in range(0, len(video_id_list), batch_size):
            yield video_id_list[video_id: video_id + batch_size] 


def extract_video_data(video_ids):
      
      extracted_data = []

      def batch_list(video_id_list, batch_size):
        for video_id in range(0, len(video_id_list), batch_size):
            yield video_id_list[video_id: video_id + batch_size] 
      

      try:
           for batch in batch_list(video_ids, maxResults):
                video_id_str = ",".join(batch)

                url = url = (
                "https://youtube.googleapis.com/youtube/v3/videos"
                f"?part=snippet,contentDetails,statistics"
                f"&id={video_id_str}"
                f"&key={API_KEY}"
            )


                response = requests.get(url)
                
                response.raise_for_status()
                
                data = response.json()

                for item in data.get('items', []):
                     video_id = item['id']
                     snippet = item['snippet']
                     contentDetails = item['contentDetails']
                     statistics = item['statistics']

                     video_data = {'video_id' : video_id,
                            'title': snippet['title'],
                            'publishedAt' : snippet['publishedAt'],
                            'duration' : contentDetails['duration'],
                            'viewCount': statistics.get('viewCount', None),
                            'likeCount': statistics.get('likeCount', None),
                            'commentCount' :  statistics.get('commentCount', None)}
                    
                     extracted_data.append(video_data)

           return extracted_data
      
      except requests.exceptions.RequestException as e:
            raise e
    
def save_to_json(extracted_data):
     file_path = f"./data/YT_data_{date.today()}.json"

     with open(file_path, 'w', encoding='utf-8') as json_outfile:
          json.dump(extracted_data, json_outfile, indent=4, ensure_ascii=False)
               



if __name__ == "__main__":
      playlistID = get_paylist_id()
      video_ids = get_video_ids(playlistID)
      video_data = extract_video_data(video_ids)
      save_to_json(video_data)


      
              